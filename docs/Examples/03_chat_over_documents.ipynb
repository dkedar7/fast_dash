{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cb94cfb",
   "metadata": {},
   "source": [
    "[![Open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/dkedar7/fast_dash/blob/docs/docs/Examples/03_chat_over_documents.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce363e40",
   "metadata": {},
   "source": [
    "This notebook is optimized to run in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15601ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fast-dash embedchain jupyter_dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f402652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fast_dash import fastdash, FastDash, Fastify, dcc\n",
    "import dash_mantine_components as dmc\n",
    "\n",
    "from embedchain import App\n",
    "from embedchain.config import QueryConfig\n",
    "\n",
    "from string import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9153b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define app configurations\n",
    "PROMPT = Template(\n",
    "    \"\"\"Use the given context to answer the question at the end.\n",
    "If you don't know the answer, say so, but don't try to make one up.\n",
    "At the end of the answer, also give the sources as a bulleted list.\n",
    "Display the answer as markdown text.\n",
    "\n",
    "Context: $context\n",
    "\n",
    "Query: $query\n",
    "\n",
    "Answer:\"\"\"\n",
    ")\n",
    "query_config = QueryConfig(template=PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99030b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define components\n",
    "openai_api_key_component = Fastify(\n",
    "    dmc.PasswordInput(\n",
    "        placeholder=\"API Key\",\n",
    "        description=\"Get yours at https://platform.openai.com/account/api-keys\",\n",
    "    ),\n",
    "    \"value\",\n",
    ")\n",
    "\n",
    "web_page_urls_component = Fastify(\n",
    "    dmc.MultiSelect(\n",
    "        description=\"Include all the reference Web URLs\",\n",
    "        placeholder=\"Enter URLs separated by commas\",\n",
    "        searchable=True,\n",
    "        creatable=True,\n",
    "    ),\n",
    "    \"data\",\n",
    ")\n",
    "\n",
    "text_component = Fastify(\n",
    "    dmc.Textarea(placeholder=\"Write your query here\", autosize=True, minRows=4), \"value\"\n",
    ")\n",
    "\n",
    "answer_component = Fastify(dcc.Markdown(style={\"text-align\": \"left\", \"padding\": \"1%\"}), \"children\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e8ddb1a-5e05-4875-9c6a-39fe76180033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callback function and deploy!\n",
    "\n",
    "@fastdash(mode=\"inline\", port=5000)\n",
    "def explore_your_knowledge_base(\n",
    "    openai_api_key: openai_api_key_component,\n",
    "    web_page_urls: web_page_urls_component,\n",
    "    youtube_urls: web_page_urls_component,\n",
    "    pdf_urls: web_page_urls_component,\n",
    "    text: text_component,\n",
    "    query: text_component,\n",
    ") -> answer_component:\n",
    "    \"\"\"\n",
    "    Input your sources and let GPT3.5 find answers. Built with Fast Dash.\n",
    "    This app uses embedchain.ai, which abstracts the entire process of loading and chunking datasets, creating embeddings, and storing them in a vector database.\n",
    "    Embedchain itself uses Langchain and OpenAI's ChatGPT API.\n",
    "    \"\"\"\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "    app = App()\n",
    "\n",
    "    if web_page_urls:\n",
    "        [app.add(\"web_page\", url[\"value\"]) for url in web_page_urls]\n",
    "\n",
    "    if youtube_urls:\n",
    "        [app.add(\"youtube_video\", url[\"value\"]) for url in youtube_urls]\n",
    "\n",
    "    if pdf_urls:\n",
    "        [app.add(\"pdf_file\", url[\"value\"]) for url in pdf_urls]\n",
    "\n",
    "    if text:\n",
    "        app.add_local(\"text\", text)\n",
    "\n",
    "    answer = app.chat(query, query_config)\n",
    "\n",
    "    return answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
